{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0c7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from systems import EpicActionRecogintionShapleyClassifier\n",
    "from datasets.pickle_dataset import MultiPickleDataset\n",
    "from models.esvs import V_MTRN, N_MTRN\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from frame_sampling import RandomSampler\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b201a490",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d58e5df18d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiPickleDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../datasets/epic-100/features/67217_train_features.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_collate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiPickleDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../datasets/epic-100/features/9668_val_features.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_collate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/epic-kitchens-100-fyrp/src/datasets/pickle_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pkl_path, features_dim)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpkl_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_cumsum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/epic-kitchens-100-fyrp/src/datasets/pickle_dataset.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpkl_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpkl_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mframe_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_frames'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpkl_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_cumsum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_cumsum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_counts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def no_collate(args):\n",
    "    return args\n",
    "\n",
    "trainloader = DataLoader(MultiPickleDataset('../datasets/epic-100/features/67217_train_features.pkl'), batch_size=1, collate_fn=no_collate, shuffle=True)\n",
    "testloader = DataLoader(MultiPickleDataset('../datasets/epic-100/features/9668_val_features.pkl'), batch_size=1, collate_fn=no_collate, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33144af",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_models = [V_MTRN(frame_count=i, hidden_layer_size=2048, dropout_count=2) for i in range(1,9)]\n",
    "n_models = [N_MTRN(frame_count=i, hidden_layer_size=2048, dropout_count=2) for i in range(1,9)]\n",
    "frame_samplers = [RandomSampler(frame_count=i, snippet_length=1, test=False) for i in range(1,9)]\n",
    "for i in range(len(v_models)):\n",
    "    try:\n",
    "        v_models[i].load_state_dict(torch.load(Path('../datasets/epic-100/models/') / f'sh_mtrn-type=verb-frames={i+1}-batch_size=512-lr=1e-05_hl=2048_dc=2.pt', map_location='cpu'))\n",
    "    except FileNotFoundError:\n",
    "        print(f'no verb model for {i+1} frames')\n",
    "    try:\n",
    "        n_models[i].load_state_dict(torch.load(Path('../datasets/epic-100/models/') / f'sh_mtrn-type=noun-frames={i+1}-batch_size=512-lr=1e-05_hl=2048_dc=2.pt', map_location='cpu'))\n",
    "    except FileNotFoundError:\n",
    "        print(f'no noun model for {i+1} frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f171a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = pd.read_csv('../datasets/epic-100/labels/EPIC_100_verb_classes.csv')['key'].to_dict()\n",
    "nouns = pd.read_csv('../datasets/epic-100/labels/EPIC_100_noun_classes.csv')['key'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471203f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_class_accuracy(model, sampler):\n",
    "    \n",
    "    def compute_accuracy(preds, labels) -> float:\n",
    "        return float((labels == preds).sum()) / len(labels)\n",
    "\n",
    "    if isinstance(model, V_MTRN):\n",
    "        classes = verbs\n",
    "        m_type=\"verb\"\n",
    "    else:\n",
    "        classes = nouns\n",
    "        m_type=\"noun\"\n",
    "\n",
    "    classifier = EpicActionRecogintionShapleyClassifier(\n",
    "        model,\n",
    "        torch.device(\"cpu\"),\n",
    "        None,\n",
    "        sampler,\n",
    "        sampler,\n",
    "        trainloader,\n",
    "        trainloader,\n",
    "        m_type\n",
    "    )\n",
    "    \n",
    "    correct_pred = {classname: 0 for classname in classes.keys()}\n",
    "    incorrect_pred = {classname: {class_n: 0 for class_n in classes.keys()} for classname in classes.keys()}\n",
    "    total_pred = {classname: 0 for classname in classes.keys()}\n",
    "    \n",
    "#     print(correct_pred)\n",
    "#     print(incorrect_pred)\n",
    "#     print(total_pred)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        validation_results = {\n",
    "            'loss': [],\n",
    "            'accuracy': [],\n",
    "            'preds': [],\n",
    "            'labels': []\n",
    "        }\n",
    "            \n",
    "        for idx, data in tqdm(enumerate(trainloader),total=len(trainloader),dynamic_ncols=True):\n",
    "            \n",
    "            batch, labels = classifier._sample_frames(data)\n",
    "            \n",
    "            logits = model(batch.to(torch.device('cpu')))\n",
    "            preds = logits.argmax(-1).cpu().numpy()\n",
    "            label_classes = labels[f'{m_type}_class']\n",
    "            \n",
    "#             print(f'pred: {preds}, label: {label_classes.cpu().numpy()}')\n",
    "\n",
    "            for label, pred in zip(label_classes.cpu().numpy(), preds):\n",
    "                if label == pred:\n",
    "                    correct_pred[label] += 1\n",
    "                incorrect_pred[label][pred] += 1\n",
    "                total_pred[label] += 1\n",
    "                        \n",
    "            validation_results['preds'].extend(list(preds))\n",
    "            validation_results['labels'].extend(list(label_classes.cpu().numpy()))\n",
    "            \n",
    "    validation_results['accuracy'] = compute_accuracy(\n",
    "        np.array(validation_results[\"labels\"]), \n",
    "        np.array(validation_results[\"preds\"])\n",
    "    )\n",
    "        \n",
    "        \n",
    "    print(validation_results['accuracy'])\n",
    "    \n",
    "#     print(correct_pred)\n",
    "#     print(incorrect_pred)\n",
    "#     print(total_pred)\n",
    "    \n",
    "    for classname, correct in correct_pred.items():\n",
    "        try:\n",
    "            accuracy = 100 * float(correct) / total_pred[classname]\n",
    "            print(\"Accuracy for class {:5s} is: {:.1f}%\".format(classes[classname], accuracy))\n",
    "        except ZeroDivisionError:\n",
    "            print(\"Did not predict class {:5s}\".format(classes[classname]))\n",
    "            \n",
    "    return classes, incorrect_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9556d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, incorrect_pred = get_per_class_accuracy(model=v_models[3], sampler=frame_samplers[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f624653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = list(classes.values())\n",
    "cnf = np.array([[x for x in y.values()] for y in incorrect_pred.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_cm = pd.DataFrame(cnf, index = [i for i in class_list],\n",
    "                  columns = [i for i in class_list])\n",
    "plt.figure(figsize = (20,14))\n",
    "cnf_matrix = sn.heatmap(df_cm, annot=False, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d298f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix.get_figure().savefig('conf.png', dpi=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d981b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b44c83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ec7af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
