{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e92cca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "from systems import EpicActionRecogintionShapleyClassifier\n",
    "from datasets.pickle_dataset import MultiPickleDataset\n",
    "from models.esvs import V_MTRN, N_MTRN\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from frame_sampling import RandomSampler\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493e1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_collate(args):\n",
    "    print(args)\n",
    "    return args\n",
    "\n",
    "trainloader = DataLoader(MultiPickleDataset('../datasets/epic-100/features/13092_test_features.pkl'), batch_size=1, collate_fn=no_collate, shuffle=True)\n",
    "testloader = DataLoader(MultiPickleDataset('../datasets/epic-100/features/9668_val_features.pkl'), batch_size=1, collate_fn=no_collate, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825dce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_models = [V_MTRN(frame_count=i) for i in range(1,9)]\n",
    "n_models = [N_MTRN(frame_count=i) for i in range(1,9)]\n",
    "frame_samplers = [RandomSampler(frame_count=i, snippet_length=1, test=True) for i in range(1,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58074d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs = pd.read_csv('../datasets/epic-100/labels/EPIC_100_verb_classes.csv')['key'].to_dict()\n",
    "nouns = pd.read_csv('../datasets/epic-100/labels/EPIC_100_noun_classes.csv')['key'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b722a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier, model: <class 'models.esvs.V_MTRN'>, type: verb, frames: 4\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x2ac1ec23d100>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x2ac1ec23d100>\n",
      "9668\n",
      "[(array([[ -3.787646 ,  27.886145 ,  -5.4291744, ...,  -5.720755 ,\n",
      "         36.021317 ,  -4.359195 ],\n",
      "       [ -3.7918136,  27.797483 ,  -5.5763116, ...,  -5.7223716,\n",
      "         35.942642 ,  -4.360745 ],\n",
      "       [ -3.809136 ,  27.99939  ,  -5.1846175, ...,  -5.7151923,\n",
      "         36.52393  ,  -4.376121 ],\n",
      "       ...,\n",
      "       [ -3.8706796,  13.580647 , -14.151562 , ...,  -5.282632 ,\n",
      "         49.29699  ,  -4.051368 ],\n",
      "       [ -3.8711371,  13.5403   , -14.134388 , ...,  -5.2840176,\n",
      "         49.275356 ,  -4.056271 ],\n",
      "       [ -3.9142551,  12.450764 , -15.009375 , ...,  -5.318194 ,\n",
      "         50.899246 ,  -4.089582 ]], dtype=float32), {'narration_id': 'P01_11_0', 'verb_class': tensor([0]), 'noun_class': tensor([2])})]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-55e58f123ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mtotal_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclassname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclassname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mxd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m#     model.eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#         with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/epic-kitchens-100-fyrp/src/systems.py\u001b[0m in \u001b[0;36mtest_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mstep_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0mstep_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/epic-kitchens-100-fyrp/src/systems.py\u001b[0m in \u001b[0;36m_sample_frames\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0mvideo_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvideo_length\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# def get_per_class_accuracy(model, loader, sampler):\n",
    "model = v_models[3]\n",
    "loader = testloader,\n",
    "sampler = frame_samplers[3]\n",
    "\n",
    "if isinstance(model, V_MTRN):\n",
    "    classes = verbs\n",
    "    m_type=\"verb\"\n",
    "else:\n",
    "    classes = nouns\n",
    "    m_type=\"noun\"\n",
    "        \n",
    "classifier = EpicActionRecogintionShapleyClassifier(\n",
    "    model,\n",
    "    torch.device(\"cpu\"),\n",
    "    None,\n",
    "    sampler,\n",
    "    None,\n",
    "    loader,\n",
    "    m_type\n",
    ")\n",
    "    \n",
    "correct_pred = {classname: 0 for classname in classes.keys()}\n",
    "incorrect_pred = {classname: {class_n: 0 for class_n in classes.keys()} for classname in classes.keys()}\n",
    "total_pred = {classname: 0 for classname in classes.keys()}\n",
    "\n",
    "xd = classifier.test_step()\n",
    "#     model.eval()\n",
    "#         with torch.no_grad():\n",
    "            \n",
    "#             validation_results = {\n",
    "#                 'loss': [],\n",
    "#                 'accuracy': [],\n",
    "#                 'preds': [],\n",
    "#                 'labels': []\n",
    "#             }\n",
    "            \n",
    "#             for idx, (batch, labels) in tqdm(enumerate(loader),total=len(loader),dynamic_ncols=True):\n",
    "                \n",
    "#                 logits = model(batch.to(torch.device('cpu')))\n",
    "#                 preds = logits.argmax(-1).cpu().numpy()\n",
    "\n",
    "#                 for label, pred in zip(labels.cpu().numpy(), preds):\n",
    "#                     if label == pred:\n",
    "#                         correct_pred[label] += 1\n",
    "# #                         print(f'idx: {idx}, Thought ' + classes[label] + ' was ' + classes[pred])\n",
    "#                     else:\n",
    "# #                         print(f'idx: {idx}, Thought ' + classes[label] + ' was ' + classes[pred])\n",
    "# #                         show_spectrogram(idx)\n",
    "#                     incorrect_pred[label][pred] += 1\n",
    "#                     total_pred[label] += 1\n",
    "                    \n",
    "                    \n",
    "#                 validation_results['preds'].extend(list(preds))\n",
    "#                 validation_results['labels'].extend(list(labels.numpy()))\n",
    "                \n",
    "#         validation_results['accuracy'] = compute_accuracy(\n",
    "#             np.array(validation_results[\"labels\"]), \n",
    "#             np.array(validation_results[\"preds\"])\n",
    "#         )\n",
    "        \n",
    "        \n",
    "#         print(validation_results['accuracy'])\n",
    "                \n",
    "        \n",
    "#         for classname, correct in correct_pred.items():\n",
    "#             accuracy = 100 * float(correct) / total_pred[classname]\n",
    "#             print(\"Accuracy for class {:5s} is: {:.1f}%\".format(classes[classname], accuracy))\n",
    "            \n",
    "#         return incorrect_pred\n",
    "    \n",
    "#     def compute_accuracy(\n",
    "#             preds,\n",
    "#             labels\n",
    "#         ) -> float:\n",
    "#             return float((labels == preds).sum()) / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(v_models[0], N_MTRN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alie = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf16de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = alie.next()\n",
    "for feature, label in data:\n",
    "    print(feature)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79473f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1bafbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V_MTRN(\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2_verb): Linear(in_features=512, out_features=97, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d8c497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91fd0cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
