{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gulpio import GulpDirectory\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/epic-100/labels/EPIC_100_train.csv', converters={'narration_id': str})['narration_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gulp_dir = GulpDirectory('../datasets/epic-100/gulp/train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67217"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gulp_dir.merged_meta_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = [d for d in df if d[:3]=='P01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../datasets/epic-100/labels/p01.pkl', 'rb') as f:\n",
    "#     p01_subset = pickle.load(f).index.values\n",
    "with open('../datasets/epic-100/esvs/f_train_mtrn-esv-min_frames=1-max_frames=8.pkl', 'rb') as f:\n",
    "    p01_subset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alie = [d for d in gulp_dir.merged_meta_dict.keys() if d[:3]=='P01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['P01_01_0', 'P01_01_1', 'P01_01_10', ..., 'P37_103_73',\n",
       "       'P37_103_8', 'P37_103_9'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P01_01_129,P01_01_105,P01_09_105,P01_07_22,P01_01_100,P01_03_16,P01_02_101,P01_02_6,P01_02_129,P01_102_29,P01_01_147,P02_134_0,P06_103_30,P09_03_33\n"
     ]
    }
   ],
   "source": [
    "subset = pd.read_csv('../subset.csv', converters={\"uid\": str})[\n",
    "            \"uid\"\n",
    "        ].values\n",
    "\n",
    "subset\n",
    "print(','.join(subset.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-54cfee561a5b>:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  index = np.where(df == subset.squeeze().tolist())\n"
     ]
    }
   ],
   "source": [
    "index = np.where(df == subset.squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicies = np.array([x in subset.squeeze().tolist() for x in p01_subset['uids'].tolist()])\n",
    "indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in p01_subset.items():\n",
    "    if type(v) == dict:\n",
    "        pass\n",
    "    elif type(v) == list:\n",
    "        new_x = []\n",
    "        for x in v:\n",
    "            new_x.append(x[indicies])\n",
    "        p01_subset[k] = new_x\n",
    "    elif v.ndim == 2:\n",
    "        p01_subset[k] = v[:,indicies]\n",
    "    elif v.ndim == 1:\n",
    "        p01_subset[k] = v[indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uids, 14\n",
      "labels, 14\n",
      "sequence_lengths, 14\n",
      "scores, 8\n",
      "sequence_idxs, 8\n",
      "shapley_values, 8\n",
      "attrs, 2\n"
     ]
    }
   ],
   "source": [
    "for k, v in p01_subset.items():\n",
    "    print(f'{k}, {len(v)}')\n",
    "#     if type(v) == list:\n",
    "#         for x in v:\n",
    "#             print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/epic-100/esvs/subset_f_train_mtrn-esv-min_frames=1-max_frames=8.pkl', 'wb') as f:\n",
    "    pickle.dump(p01_subset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(p01_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
