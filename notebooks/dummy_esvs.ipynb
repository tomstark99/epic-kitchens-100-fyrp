{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de819751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gulpio2 import GulpDirectory\n",
    "from frame_sampling import RandomSampler\n",
    "from datasets.gulp_dataset import GulpDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvideo.samplers import frame_idx_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41abd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_frames(video_length):\n",
    "    if video_length < n_frames:\n",
    "        raise ValueError(f\"Video too short to sample {n_frames} from\")\n",
    "    sample_idxs = np.array(frame_idx_to_list(frame_sampler.sample(video_length)))\n",
    "    return sample_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "741ab526",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_train = GulpDataset('../datasets/epic-100/gulp/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46c7db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 8\n",
    "frame_sampler = RandomSampler(frame_count=n_frames, snippet_length=1, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5565a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(rgb_train, batch_size=1)\n",
    "it = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1da40ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video, rgb_meta = it.next()\n",
    "video = torch.cat(video)\n",
    "video.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7dfe3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    'verb': rgb_meta['verb_class'].item(),\n",
    "    'noun': rgb_meta['noun_class'].item()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de707270",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = subsample_frames(rgb_meta['num_frames'].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bff09ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 14, 23, 32, 42, 51, 60, 70])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23842967",
   "metadata": {},
   "outputs": [],
   "source": [
    "esvs = torch.softmax(torch.rand((1,n_frames,397)), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3172a13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 397])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esvs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66c335a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'narration_id': ['P01_01_103'],\n",
       " 'participant_id': ['P01'],\n",
       " 'video_id': ['P01_01'],\n",
       " 'narration_timestamp': ['00:08:03.919'],\n",
       " 'start_timestamp': ['00:08:05.22'],\n",
       " 'stop_timestamp': ['00:08:07.21'],\n",
       " 'start_frame': tensor([29113]),\n",
       " 'stop_frame': tensor([29232]),\n",
       " 'narration': ['take container and lid'],\n",
       " 'verb': ['take'],\n",
       " 'verb_class': tensor([0]),\n",
       " 'noun': ['container'],\n",
       " 'noun_class': tensor([21]),\n",
       " 'all_nouns': [('container',), ('lid',)],\n",
       " 'all_noun_classes': [tensor([21]), tensor([6])],\n",
       " 'frame_size': [tensor([256]), tensor([456]), tensor([3])],\n",
       " 'num_frames': tensor([120])}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afe63c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_meta['num_frames'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7083b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
